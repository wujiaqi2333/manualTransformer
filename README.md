# manualTransformer
一个从头开始实现的Transformer模型，用于小规模文本建模任务。本项目完整实现了Transformer架构，包括multi-head self-attention、position-wise FFN、残差连接与LayerNorm、位置编码等核心组件，并在WikiText-2数据集上进行了训练和消融实验。
